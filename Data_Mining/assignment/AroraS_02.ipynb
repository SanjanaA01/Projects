{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AroraS_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsC5kRq4AF4t"
      },
      "source": [
        "# Student : Arora, Sanjana (V00966221)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc3BGzDsAMpf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0JJIjscDD4z"
      },
      "source": [
        "Please upload elections_clean.csv provided within the zip folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otFOkZpbT8LK"
      },
      "source": [
        "df = pd.read_csv('elections_clean.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDB1zJNGUNSO",
        "outputId": "16d132ec-399a-4df2-ea90-bc055ab43f4d"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'votes', 'UnemploymentRate2015', 'MedHHInc2014',\n",
              "       'PerCapitaInc', 'PovertyAllAgesPct2014', 'Deep_Pov_All', 'Population',\n",
              "       'Area in square miles - Total area', 'PopDensity', 'TOT_MALE_rate',\n",
              "       'TOT_FEMALE_rate', 'voter_turnout_rate', 'Democrat', 'State', 'County',\n",
              "       'Education', 'Religion', 'Old', 'Young', 'Adult', 'EthnicMale',\n",
              "       'EthnicFemale'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYHJUTJ4PxDt"
      },
      "source": [
        "subset = df[['Education', 'Religion', 'EthnicMale', 'EthnicFemale', 'Democrat']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4GNNpREP6Uk",
        "outputId": "85820407-ba47-4d6f-e0f9-32d812465b54"
      },
      "source": [
        "subset.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Education', 'Religion', 'EthnicMale', 'EthnicFemale', 'Democrat'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "coN1E2BHKj5Y",
        "outputId": "c8965e05-19ae-4d7f-b1db-81b9d01b07d2"
      },
      "source": [
        "subset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Education</th>\n",
              "      <th>Religion</th>\n",
              "      <th>EthnicMale</th>\n",
              "      <th>EthnicFemale</th>\n",
              "      <th>Democrat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OnlyDiploma</td>\n",
              "      <td>Other Misc</td>\n",
              "      <td>WHITE_MALE_rate</td>\n",
              "      <td>WHITE_FEMALE_rate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OnlyDiploma</td>\n",
              "      <td>Catholic</td>\n",
              "      <td>WHITE_MALE_rate</td>\n",
              "      <td>WHITE_FEMALE_rate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>College</td>\n",
              "      <td>Christian Generic</td>\n",
              "      <td>WHITE_MALE_rate</td>\n",
              "      <td>WHITE_FEMALE_rate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OnlyDiploma</td>\n",
              "      <td>Catholic</td>\n",
              "      <td>WHITE_MALE_rate</td>\n",
              "      <td>WHITE_FEMALE_rate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>College</td>\n",
              "      <td>Catholic</td>\n",
              "      <td>WHITE_MALE_rate</td>\n",
              "      <td>WHITE_FEMALE_rate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Education           Religion       EthnicMale       EthnicFemale  Democrat\n",
              "0  OnlyDiploma         Other Misc  WHITE_MALE_rate  WHITE_FEMALE_rate         0\n",
              "1  OnlyDiploma           Catholic  WHITE_MALE_rate  WHITE_FEMALE_rate         0\n",
              "2      College  Christian Generic  WHITE_MALE_rate  WHITE_FEMALE_rate         0\n",
              "3  OnlyDiploma           Catholic  WHITE_MALE_rate  WHITE_FEMALE_rate         0\n",
              "4      College           Catholic  WHITE_MALE_rate  WHITE_FEMALE_rate         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDsZ5KxyURYV"
      },
      "source": [
        "#Calculating the entropy\n",
        "\n",
        "def entropy(Y): # Y is the Target Columns\n",
        "  values, counts = np.unique(Y,return_counts = True)\n",
        "  for i in range(len(values)):\n",
        "    prob = counts[i]/np.sum(counts) # calculating the probability\n",
        "    h = np.sum(-(prob)*np.log2(prob))\n",
        "  return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e4HOBuRW98r"
      },
      "source": [
        "#Calculating the Information Gain\n",
        "def InfoGain(dataset,split_feature_name, Y):\n",
        "  total_h = entropy(dataset[Y]) \n",
        "  values, counts = np.unique(dataset[split_feature_name],return_counts = True)\n",
        "  weighted_h = 0\n",
        "  for i in range(len(values)):\n",
        "    prob = counts[i]/np.sum(counts)\n",
        "    feature = dataset.where(dataset[split_feature_name]==values[i]).dropna()[Y]\n",
        "    h = entropy(feature)\n",
        "    weighted_h = weighted_h + prob*h\n",
        "  IG = total_h - weighted_h\n",
        "  return IG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXUtvNQ2eJpu"
      },
      "source": [
        "DecisionClassifier function takes the following input parameters:\n",
        "1. Dataset (This reduces are we recurse in this function)\n",
        "2. Original Dataset (The Training/Validation Dataset for out classification)\n",
        "3. Filter_node_class (The values of target vector (Democrat) that called the DecisionClassifier recursion\n",
        "4. Depth (The max depth of the tree- User can change this value for pruning the tree)\n",
        "5. Length (parameter used by the function to calculate the max depth of the tree \n",
        "\n",
        "DecisionClassifier function outputs the following input parameters:\n",
        "1. Tree\n",
        "2. Names of the feature appearing in decision stump\n",
        "3. Max depth of the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BniBMGpaUfu"
      },
      "source": [
        "def DecisionClassifier(dataset,originaldata,features,Y,depth=20,filter_node_class = None,height=-1, length=[], feat=[]):\n",
        "      \n",
        "      #Storing and Adding the length of the tree\n",
        "      height=height\n",
        "      length.append(height)\n",
        "      \n",
        "      # Checking if all target values have same values left\n",
        "      if (len(np.unique(dataset[Y])) <= 1):\n",
        "          \n",
        "          return np.unique(dataset[Y])[0], length, feat # return the value and length of the tree\n",
        "      \n",
        "      # if dataset has got empty\n",
        "      elif (len(dataset)==0 or height==depth) :\n",
        "        \n",
        "        # index of the mode target feature value in dataset\n",
        "        index = np.argmax(np.unique(originaldata[Y],return_counts=True)[1])\n",
        "        mode = np.unique(originaldata[Y])[index]\n",
        "        return mode, length,feat #returning the target feature value occuring maximum number of times in original dataset\n",
        "      \n",
        "      # if the number of features have got zero, returning the mode target feature value indicated by the parent node that called the DecisionClassifier recursion\n",
        "      elif (len(features) ==0):\n",
        "        return filter_node_class, length,feat\n",
        "      \n",
        "      \n",
        "      # if none of the conditions are true, growing the tree\n",
        "      else:\n",
        "        \n",
        "        # growing the tree\n",
        "        # assigning parent node class feature values as the selected target feature value having max. no. of occurrences\n",
        "          index = np.argmax(np.unique(dataset[Y],return_counts=True)[1])\n",
        "          filter_node_class  = np.unique(dataset[Y])[index]\n",
        "          \n",
        "         # selecting the feature which best splits the dataset \n",
        "          item_vals = [InfoGain(dataset,feature,Y) for feature in features]\n",
        "          \n",
        "          # best feature is the feature having maximum information gain about the target feature\n",
        "          best_featureindex = np.argmax(item_vals)\n",
        "          best_feature = features[best_featureindex]\n",
        "         \n",
        "          # tree structure\n",
        "          tree = {best_feature:{}}\n",
        "          feat.append(best_feature)\n",
        "          # iterating over all features except for the best feature\n",
        "          features = [i for i in features if i != best_feature]\n",
        "        # Adding the height as a feature is getting added to the decision stump\n",
        "          height+= 1\n",
        "          \n",
        "        \n",
        "          \n",
        "            #finding the dataset corresponding the best feature for further analysis\n",
        "          for vals in np.unique(dataset[best_feature]):\n",
        "              \n",
        "              sub_data = dataset.where(dataset[best_feature] == vals).dropna()  \n",
        "              subtree, length, feat = DecisionClassifier(sub_data,dataset,features,Y,depth,filter_node_class,height=height, length=length,feat=feat)\n",
        "            \n",
        "            \n",
        "            # adding subtree, under the grown tree\n",
        "              tree[best_feature][vals] = subtree\n",
        "          return tree, length, feat     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdzFvKigfxg-"
      },
      "source": [
        "def prediction(query,tree,default = 1):\n",
        "    for key in list(query.keys()):\n",
        "        #check for every key in the query, if the feature exists in the keys of the tree\n",
        "        if key in list(tree.keys()):\n",
        "            \n",
        "            try:\n",
        "                result = tree[key][query[key]] \n",
        "            except:\n",
        "              #if the feature does not exist return default value\n",
        "                return default\n",
        "  \n",
        "            \n",
        "            result = tree[key][query[key]]\n",
        "            \n",
        "            if isinstance(result,dict):\n",
        "                return prediction(query,result)\n",
        "\n",
        "            else:\n",
        "                return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLxZAMC-fy7P"
      },
      "source": [
        "def error_calc(data,tree,target_attribute_name):\n",
        "    # generating new queries as dictionaries from the dataset that is devoid of the target feature\n",
        "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
        "    \n",
        "    # dataframe capturing predicted target values\n",
        "    predicted = pd.DataFrame(columns=[\"predicted\"])  \n",
        "\n",
        "    #Calculate the prediction accuracy and error rates\n",
        "    for i in range(len(data)):\n",
        "        predicted.loc[i,\"predicted\"] = prediction(queries[i],tree,1)\n",
        "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[target_attribute_name])/len(data))*100,'%')\n",
        "    print('The Mean Absolute Error: ', np.mean(np.square(predicted[\"predicted\"] - np.array(data[target_attribute_name])))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L46J2rwpfRK0"
      },
      "source": [
        "**Function for Splitting the dataset into testing and training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhS5__aZmTV5"
      },
      "source": [
        "def train_validation_split(dataset):\n",
        "    validation_split = .3\n",
        "    dataset_size = len(dataset)\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    training_data = dataset.iloc[split:].reset_index(drop=True)\n",
        "    validation_data = dataset.iloc[:split].reset_index(drop=True)\n",
        "    return training_data,validation_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX-gG6zSfDxb"
      },
      "source": [
        "**Shuffling the dataset and splitting the dataset into training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy1cDK8Bncuz",
        "outputId": "387f0a74-8047-4d41-eac0-8a0948a59b1f"
      },
      "source": [
        "subset = subset.sample(frac = 1)\n",
        "training_data = train_validation_split(subset)[0]\n",
        "validation_data = train_validation_split(subset)[1] \n",
        "print(training_data.shape,validation_data.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2202, 5) (943, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrFDMzkO5zzN"
      },
      "source": [
        "Q2. **Implementing the decision tree from scratch **\n",
        "\n",
        "User can input desired depth along with other parameters in DecisionClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R8YO9686CZd"
      },
      "source": [
        "Maximum Depth of the tree is 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oya6YbJuiFD9",
        "outputId": "ea1e025f-be0b-480b-8bef-990dcdebeb03"
      },
      "source": [
        "tree, length,feat = DecisionClassifier(training_data,training_data,training_data.columns[:-1],'Democrat')\n",
        "import pprint\n",
        "pprint.pprint(tree)\n",
        "print('The max depth of the tree is:', max(length))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Education': {'BachelorOrHigher': {'Religion': {'Amish': 0.0,\n",
            "                                                 'Catholic': {'EthnicFemale': {'BLACK_FEMALE_rate': 1.0,\n",
            "                                                                               'WHITE_FEMALE_rate': {'EthnicMale': {'ASIAN_MALE_rate': 1.0,\n",
            "                                                                                                                    'WHITE_MALE_rate': 1.0}}}},\n",
            "                                                 'Christian Generic': {'EthnicFemale': {'BLACK_FEMALE_rate': 1.0,\n",
            "                                                                                        'WHITE_FEMALE_rate': {'EthnicMale': {'WHITE_MALE_rate': 0.0}}}},\n",
            "                                                 'Other': {'EthnicMale': {'WHITE_MALE_rate': {'EthnicFemale': {'WHITE_FEMALE_rate': 0.0}}}}}},\n",
            "               'College': {'EthnicFemale': {'BLACK_FEMALE_rate': {'EthnicMale': {'BLACK_MALE_rate': 1.0,\n",
            "                                                                                 'WHITE_MALE_rate': {'Religion': {'Catholic': 1.0,\n",
            "                                                                                                                  'Christian Generic': 1.0}}}},\n",
            "                                            'NATIVE_AMERICAN_FEMALE_rate': {'Religion': {'Catholic': {'EthnicMale': {'NATIVE_AMERICAN_MALE_rate': 1.0,\n",
            "                                                                                                                     'WHITE_MALE_rate': 0.0}},\n",
            "                                                                                         'Christian Generic': 0.0}},\n",
            "                                            'WHITE_FEMALE_rate': {'Religion': {'Catholic': {'EthnicMale': {'WHITE_MALE_rate': 0.0}},\n",
            "                                                                               'Christian Generic': {'EthnicMale': {'BLACK_MALE_rate': 0.0,\n",
            "                                                                                                                    'WHITE_MALE_rate': 0.0}},\n",
            "                                                                               'Mormon': 0.0,\n",
            "                                                                               'Other': {'EthnicMale': {'WHITE_MALE_rate': 0.0}}}}}},\n",
            "               'LessthanDiploma': {'Religion': {'Catholic': {'EthnicMale': {'WHITE_MALE_rate': {'EthnicFemale': {'WHITE_FEMALE_rate': 1.0}}}},\n",
            "                                                'Christian Generic': {'EthnicFemale': {'BLACK_FEMALE_rate': 1.0,\n",
            "                                                                                       'WHITE_FEMALE_rate': 0.0}}}},\n",
            "               'OnlyDiploma': {'EthnicFemale': {'BLACK_FEMALE_rate': {'EthnicMale': {'BLACK_MALE_rate': {'Religion': {'Christian Generic': 1.0}},\n",
            "                                                                                     'WHITE_MALE_rate': {'Religion': {'Catholic': 1.0,\n",
            "                                                                                                                      'Christian Generic': 1.0}}}},\n",
            "                                                'NATIVE_AMERICAN_FEMALE_rate': {'Religion': {'Catholic': {'EthnicMale': {'NATIVE_AMERICAN_MALE_rate': 1.0}},\n",
            "                                                                                             'Christian Generic': 0.0}},\n",
            "                                                'WHITE_FEMALE_rate': {'Religion': {'Catholic': {'EthnicMale': {'WHITE_MALE_rate': 0.0}},\n",
            "                                                                                   'Christian Generic': {'EthnicMale': {'BLACK_MALE_rate': 0.0,\n",
            "                                                                                                                        'WHITE_MALE_rate': 0.0}},\n",
            "                                                                                   'Mormon': 0.0,\n",
            "                                                                                   'Other': 0.0,\n",
            "                                                                                   'Other Misc': 0.0}}}}}}\n",
            "The max depth of the tree is: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BugmDSi1noYz"
      },
      "source": [
        "Number of feature repeating in decision stumps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJFiF_MGkqwb",
        "outputId": "7ec57ebf-59c5-4d88-e24e-fd961b90fa78"
      },
      "source": [
        "Names = np.unique(feat,return_counts=True)[0]\n",
        "Number = np.unique(feat,return_counts=True)[1]\n",
        "print('The repeating features in decision stump:', Names, 'in the respective order of:', Number)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The repeating features in decision stump: ['Education' 'EthnicFemale' 'EthnicMale' 'Religion'] in the respective order of: [ 1  7 13  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7RracS76Jh_"
      },
      "source": [
        "Training Accuracy & Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9koRlXeRaoe",
        "outputId": "8376099e-95db-4976-ecee-5ed5b50cb1b9"
      },
      "source": [
        "# Training Error\n",
        "error_calc(training_data,tree,'Democrat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction accuracy is:  91.46230699364214 %\n",
            "The Mean Absolute Error:  0.08537693006357856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUiy468I6Ool"
      },
      "source": [
        "Testing Accuracy & Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itRAaQZ3RBGa",
        "outputId": "8fe7a226-79a3-432d-dd29-704f82008984"
      },
      "source": [
        "# Validation Error\n",
        "error_calc(validation_data,tree,'Democrat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction accuracy is:  90.98621420996818 %\n",
            "The Mean Absolute Error:  0.09013785790031813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzmcbNze8i1H"
      },
      "source": [
        "**Bonus Q1 Making more categorical related features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovqDGgLC8vHT",
        "outputId": "7ce550bc-f899-4453-a7f1-f200874d1274"
      },
      "source": [
        "df['Age'] = df[[ 'Old', 'Young', 'Adult']].idxmax(axis=1)\n",
        "\n",
        "#binning income related features\n",
        "bins = [0,1, 2, 3, 4, 5]\n",
        "df['binned_Hincome'] = pd.qcut(df['MedHHInc2014'], q= 6, labels=bins)\n",
        "df['binned_PerCincome'] = pd.qcut(df['PerCapitaInc'], q= 6, labels=bins)\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'votes', 'UnemploymentRate2015', 'MedHHInc2014',\n",
              "       'PerCapitaInc', 'PovertyAllAgesPct2014', 'Deep_Pov_All', 'Population',\n",
              "       'Area in square miles - Total area', 'PopDensity', 'TOT_MALE_rate',\n",
              "       'TOT_FEMALE_rate', 'voter_turnout_rate', 'Democrat', 'State', 'County',\n",
              "       'Education', 'Religion', 'Old', 'Young', 'Adult', 'EthnicMale',\n",
              "       'EthnicFemale', 'Age', 'binned_Hincome', 'binned_PerCincome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZInmMBvC98C"
      },
      "source": [
        "subset1 = df[['Education', 'Religion', 'EthnicMale', 'EthnicFemale','Age', 'binned_Hincome', 'binned_PerCincome', 'Democrat']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX5zcpbtDNaT",
        "outputId": "99b7e8c3-0483-439d-8f38-4eda97a7cc7a"
      },
      "source": [
        "subset1 = subset1.sample(frac = 1)\n",
        "training_data1 = train_validation_split(subset1)[0]\n",
        "validation_data1 = train_validation_split(subset1)[1] \n",
        "print(training_data1.shape,validation_data1.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2202, 8) (943, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPjvhLs5DaG-"
      },
      "source": [
        "#Training the decision tree with new data\n",
        "tree_new, length_new, feat_new = DecisionClassifier(training_data1,training_data1,training_data1.columns[:-1],'Democrat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwgvIo_yDman",
        "outputId": "d999b9ec-36a8-4c3c-b104-4141192c3fb9"
      },
      "source": [
        "print('The max depth of the tree is:', max(length_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max depth of the tree is: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcVaysVJDp_l",
        "outputId": "e3df8532-d03e-49a2-ccf4-24222cd0d555"
      },
      "source": [
        "# Training Error\n",
        "error_calc(training_data1,tree_new,'Democrat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction accuracy is:  92.41598546775658 %\n",
            "The Mean Absolute Error:  0.07584014532243415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxNiDGnaDx1X",
        "outputId": "837e568d-ab18-444a-f2c2-1913e2883a04"
      },
      "source": [
        "# Validation Error\n",
        "error_calc(validation_data1,tree_new,'Democrat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction accuracy is:  90.66808059384942 %\n",
            "The Mean Absolute Error:  0.09331919406150584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWxhMkVBEFHb"
      },
      "source": [
        "By adding more categories, the training error changed from approx. 0.085 to 0.075, while testing error increased slightly by 0.090 to 0.093.\n",
        "\n",
        "The length of the tree increased from 3 to 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Em7SsRTFRur"
      },
      "source": [
        "Referred Lecture slides and https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/"
      ]
    }
  ]
}