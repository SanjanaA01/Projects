{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AroraS_07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPhlHbZFO_sx"
      },
      "source": [
        "Student: Arora, Sanjana, V00966221"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjvqGNmel_fQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as sps\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE8AliWwmp5z"
      },
      "source": [
        "df = pd.read_csv('elections_clean.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj611-pone_m"
      },
      "source": [
        "subset = df[['Education', 'Religion', 'EthnicMale','EthnicFemale']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj9URmm6inEm",
        "outputId": "87c99271-c5a2-4b71-c7ac-386eb1f2286e"
      },
      "source": [
        "df_transformed = pd.get_dummies(subset)\n",
        "len(df_transformed.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4lIRPPRLoKeK",
        "outputId": "b42ac6a4-0f7a-430d-8c37-8640b3c0af55"
      },
      "source": [
        "df_transformed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Education_BachelorOrHigher</th>\n",
              "      <th>Education_College</th>\n",
              "      <th>Education_LessthanDiploma</th>\n",
              "      <th>Education_OnlyDiploma</th>\n",
              "      <th>Religion_Amish</th>\n",
              "      <th>Religion_Catholic</th>\n",
              "      <th>Religion_Christian Generic</th>\n",
              "      <th>Religion_Mormon</th>\n",
              "      <th>Religion_Other</th>\n",
              "      <th>Religion_Other Misc</th>\n",
              "      <th>EthnicMale_ASIAN_MALE_rate</th>\n",
              "      <th>EthnicMale_BLACK_MALE_rate</th>\n",
              "      <th>EthnicMale_NATIVE_AMERICAN_MALE_rate</th>\n",
              "      <th>EthnicMale_WHITE_MALE_rate</th>\n",
              "      <th>EthnicFemale_BLACK_FEMALE_rate</th>\n",
              "      <th>EthnicFemale_NATIVE_AMERICAN_FEMALE_rate</th>\n",
              "      <th>EthnicFemale_WHITE_FEMALE_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Education_BachelorOrHigher  ...  EthnicFemale_WHITE_FEMALE_rate\n",
              "0                           0  ...                               1\n",
              "1                           0  ...                               1\n",
              "2                           0  ...                               1\n",
              "3                           0  ...                               1\n",
              "4                           0  ...                               1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XTHAUJtoOrh"
      },
      "source": [
        "X = df_transformed.iloc[:,:].values\n",
        "Y = df['Democrat'].values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxHImjc-oRU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIjGi48FoURV"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFGaxDNUiv8t"
      },
      "source": [
        "dataset = df[['Education', 'Religion', 'EthnicMale', 'EthnicFemale', 'Democrat']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtuVI3WRoYwl"
      },
      "source": [
        "rf_clf = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAZKFTZzoiXe",
        "outputId": "838c4f89-143e-4bfa-8fb3-772211004bf1"
      },
      "source": [
        "rf_clf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=3, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICPDugLcolBG"
      },
      "source": [
        "Y_pred = rf_clf.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joCtqoWbozK2",
        "outputId": "b7a96b98-5526-4a62-80b3-6cce0f1e60d7"
      },
      "source": [
        "print(\"The training mean absolute error: {0:.4f}\\n\".format(mean_absolute_error(Y_train,Y_pred))) \n",
        "print(\"The training accuracy score: {0:.4f}\\n\".format(accuracy_score(Y_train,Y_pred))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training mean absolute error: 0.0977\n",
            "\n",
            "The training accuracy score: 0.9023\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtNNP_49pD6h"
      },
      "source": [
        "Y_predtest = rf_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7uG04zkpIUg",
        "outputId": "3d1dde3a-1816-4fa0-f215-9f349c281711"
      },
      "source": [
        "print(\"The testing mean absolute error: {0:.4f}\\n\".format(mean_absolute_error(Y_test,Y_predtest))) \n",
        "print(\"The testing accuracy score: {0:.4f}\\n\".format(accuracy_score(Y_test,Y_predtest)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The testing mean absolute error: 0.0784\n",
            "\n",
            "The testing accuracy score: 0.9216\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0fvIIs4mGk"
      },
      "source": [
        "*Conclusion relating to random forests in the end*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aloOKLExi8W"
      },
      "source": [
        "**Bonus Question**: *Random Forest from Scratch*\n",
        "\n",
        "The codes for random forest have been inherited from the codes used for preparing decision trees as the core logics for creating the decision trees following the entropy based split criteria remain the same.\n",
        "\n",
        "I append all the created trees in a dictionary in the \"**RandomForestTrain**\" function. \n",
        "Use the majority voting of the predictions output by each of the tree in \"**RandomForest_Predict**\" function.The default value used for prediction is 1. \n",
        "\n",
        "Store all the predicted values in a dataframe columns and calculate the mean squared error and accuracy scores in \"**RandomForestTest**\" function. \n",
        "\n",
        "Further, there is a change in decisionclassifier function, wherein, subspace is getting sampled by randomly choosing sqrt(total number of features) for each subspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti3vC8tdKl3J"
      },
      "source": [
        "#Calculating the entropy\n",
        "\n",
        "def entropy(Y): # Y is the Target Columns\n",
        "  values, counts = np.unique(Y,return_counts = True)\n",
        "  for i in range(len(values)):\n",
        "    prob = counts[i]/np.sum(counts) # calculating the probability\n",
        "    h = np.sum(-(prob)*np.log2(prob))\n",
        "  return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c79T0b6tmEp_"
      },
      "source": [
        "#Calculating the Information Gain\n",
        "def InfoGain(dataset,split_feature_name, Y):\n",
        "  total_h = entropy(dataset[Y]) \n",
        "  values, counts = np.unique(dataset[split_feature_name],return_counts = True)\n",
        "  #initiating the weighted entropy from 0\n",
        "  weighted_h = 0\n",
        "  for i in range(len(values)):\n",
        "    prob = counts[i]/np.sum(counts)\n",
        "    feature = dataset.where(dataset[split_feature_name]==values[i]).dropna()[Y]\n",
        "    h = entropy(feature)\n",
        "    # Adding values to the entropy as we traverse through the features\n",
        "    weighted_h = weighted_h + prob*h\n",
        "  IG = total_h - weighted_h\n",
        "  return IG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viQZnHwCmLsl"
      },
      "source": [
        "def DecisionClassifier(dataset,originaldata,features,Y,depth=20,filter_node_class = None):\n",
        "      \n",
        "      # Checking if all target values have same values left\n",
        "      if (len(np.unique(dataset[Y])) <= 1):\n",
        "          \n",
        "          return np.unique(dataset[Y])[0] # return the value and length of the tree\n",
        "      \n",
        "      # if dataset has got empty\n",
        "      elif (len(dataset)==0) :\n",
        "        \n",
        "        # index of the mode target feature value in dataset\n",
        "        index = np.argmax(np.unique(originaldata[Y],return_counts=True)[1])\n",
        "        mode = np.unique(originaldata[Y])[index]\n",
        "        return mode #returning the target feature value occuring maximum number of times in original dataset\n",
        "      \n",
        "      # if the number of features have got zero, returning the mode target feature value indicated by the parent node that called the DecisionClassifier recursion\n",
        "      elif (len(features) ==0):\n",
        "        return filter_node_class\n",
        "      \n",
        "      \n",
        "      # if none of the conditions are true, growing the tree\n",
        "      else:\n",
        "        \n",
        "        # growing the tree\n",
        "        # assigning parent node class feature values as the selected target feature value having max. no. of occurrences\n",
        "          index = np.argmax(np.unique(dataset[Y],return_counts=True)[1])\n",
        "          filter_node_class  = np.unique(dataset[Y])[index]\n",
        "          \n",
        "          #Implementing the subspace sampling. Draw a number of m = sqrt(p) feature\n",
        "          features = np.random.choice(features,size=np.int(np.sqrt(len(features))),replace=False)\n",
        "         # selecting the feature which best splits the dataset \n",
        "          item_vals = [InfoGain(dataset,feature,Y) for feature in features]\n",
        "          \n",
        "          # best feature is the feature having maximum information gain about the target feature\n",
        "          best_featureindex = np.argmax(item_vals)\n",
        "          best_feature = features[best_featureindex]\n",
        "         \n",
        "          # tree structure\n",
        "          tree = {best_feature:{}}\n",
        "          \n",
        "          # iterating over all features except for the best feature\n",
        "          features = [i for i in features if i != best_feature]\n",
        "        \n",
        "          #finding the dataset corresponding the best feature for further analysis\n",
        "          for vals in np.unique(dataset[best_feature]):\n",
        "              \n",
        "              sub_data = dataset.where(dataset[best_feature] == vals).dropna()  \n",
        "              subtree = DecisionClassifier(sub_data,dataset,features,Y,depth,filter_node_class)\n",
        "            \n",
        "            \n",
        "            # adding subtree, under the grown tree\n",
        "              tree[best_feature][vals] = subtree\n",
        "          return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izPijNymmOkl"
      },
      "source": [
        "def predict(query,tree,default = 1):\n",
        "        \n",
        "    for key in list(query.keys()):\n",
        "        if key in list(tree.keys()):\n",
        "            try:\n",
        "                result = tree[key][query[key]] \n",
        "            except:\n",
        "                return default\n",
        "            result = tree[key][query[key]]\n",
        "            if isinstance(result,dict):\n",
        "                return predict(query,result)\n",
        "\n",
        "            else:\n",
        "                return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_F5N04ImRs3"
      },
      "source": [
        "def train_validation_split(dataset):\n",
        "    validation_split = .3\n",
        "    dataset_size = len(dataset)\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    training_data = dataset.iloc[split:].reset_index(drop=True)\n",
        "    validation_data = dataset.iloc[:split].reset_index(drop=True)\n",
        "    return training_data,validation_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJzhrba6mUuT"
      },
      "source": [
        "def RandomForestTrain(dataset,Y,number_of_Trees):\n",
        "    #Creating an empty list to store the number of trees\n",
        "    random_forest_sub_tree = []\n",
        "    \n",
        "    # To create the number of trees as mentioned by user\n",
        "    for i in range(number_of_Trees):\n",
        "        # Shuffling the dataset to create a number of bootstrap sampled datasets from the original dataset \n",
        "        bootstrap_data = dataset.sample(frac=1,replace=True)\n",
        "        \n",
        "        #Create a training and a testing dataset by calling the train_validation_split function\n",
        "        bootstrap_training_data, bootstrap_testing_data = train_validation_split(bootstrap_data)\n",
        "        \n",
        "        \n",
        "        #Growing the tree\n",
        "        #Creating trees with bootstrapped datasets\n",
        "        random_forest_sub_tree.append(DecisionClassifier(bootstrap_training_data,bootstrap_training_data,bootstrap_training_data.drop(labels=[Y],axis=1).columns,Y))\n",
        "        \n",
        "    return random_forest_sub_tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2_9A70RI-y"
      },
      "source": [
        "def RandomForestTest(data,random_forest_tree,target_attribute_name):\n",
        "  #Creating an empty column to store prediction values\n",
        "    data['predictions'] = None\n",
        "    for i in range(len(data)):\n",
        "        queries = data.iloc[i,:].drop(target_attribute_name).to_dict()\n",
        "        #Storing the prediction outcomes in the column\n",
        "        data.loc[i,'predictions'] = RandomForest_Predict(queries,random_forest_tree,default=1)\n",
        "    #calculating the accuracy scores\n",
        "    accuracy = sum(data['predictions'] == data[target_attribute_name])/len(data)*100\n",
        "    # Calculating the mean squared error\n",
        "    MAE = np.mean(np.square(data['predictions'] - np.array(data[target_attribute_name].astype(int))))\n",
        "    return accuracy, MAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erYw7LDVQ-12"
      },
      "source": [
        "def RandomForest_Predict(query,random_forest_tree,default=1):\n",
        "    predictions = []\n",
        "    #for each tree in the randomforest dictionary\n",
        "    for tree in random_forest_tree:\n",
        "        predictions.append(predict(query,tree,default))\n",
        "        # taking majority voting for decision\n",
        "    return sps.mode(predictions)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnfuSScZmX5S"
      },
      "source": [
        "training_data1,testing_data = train_validation_split(dataset)\n",
        "random_forest = RandomForest_Train(training_data1,'Democrat',50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YanM_Sdmh6N",
        "outputId": "029e7ca0-7147-4a1e-90d6-b7768d62ec14"
      },
      "source": [
        "Testing_accuracy, Testing_MSE = RandomForestTest(testing_data,random_forest,'Democrat')\n",
        "print('The testing accuracy of model made from scratch:',Testing_accuracy )\n",
        "print('The testing MAE of model:',Testing_MSE )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The testing accuracy of model made from scratch: 87.0625662778367\n",
            "The testing MAE of model: 0.12937433722163308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGoU975wf45C",
        "outputId": "a394537e-cfb8-449a-fd0d-465efa6129ca"
      },
      "source": [
        "Training_accuracy, Training_MSE = RandomForestTest(training_data1,random_forest,'Democrat')\n",
        "print('The training accuracy of made from scratch:',Training_accuracy )\n",
        "print('The training MAE of model:',Training_MSE )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy of made from scratch: 87.92007266121708\n",
            "The training MAE of model: 0.12079927338782924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMR3dcydhFkZ"
      },
      "source": [
        "Referred online materials from https://stats.stackexchange.com/questions/295868/why-is-tree-correlation-a-problem-when-working-with-bagging/295883\n",
        "\n",
        "2. https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHqJ6mJaqD3R"
      },
      "source": [
        "According to me, the random forests are not performing better on this data due to the following observations:\n",
        "\n",
        " 1. The mean absolute training error of random forest  0.0909 is higher than mean absolute training error of decision trees 0.0854157201272149 made by using the sklearn library. \n",
        "\n",
        "2. Also, **the decision trees created manually**  are performing **better** as compared to the random forests. The testing Mean Absolute Error (MAE) for random forest **0.0911** is higher than the MAE of manually created decision trees **0.08695652173913043**.\n",
        "\n",
        "3. While the differences in mean absolute testing error of random forest (0.9089) and mean absolute testing error of decision tree (0.09427966101694915) are quite low.\n",
        "\n",
        "4. Training MAE of manually created Decision Trees (0.08764759309718438) is much better than training MAE of random forest 0.0909.\n",
        "\n",
        "The probable reason of random forest not performing better than decision trees could be pruning the decision trees to the depth of 3.Further, the random forest performs bootstrapping on the input training data, it is possible that there are multiple repeating feature values that keep on occuring in shuffling of datasets and features."
      ]
    }
  ]
}